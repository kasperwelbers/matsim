---
title: "README"
author: Kasper Welbers
output: md_document
editor_options: 
  chunk_output_type: console
---

Example
============

```{r, eval=F}
devtools::install_github('kasperwelbers/matsim')
```

```{r}
library(matsim)
library(Matrix)
library(microbenchmark)
```

Several options for filtering results. Filtering is performed on the fly, after each iteration (rows in m).

```{r}
set.seed(1)
m = Matrix::rsparsematrix(5,10,0.5)
tcrossprod_sparse(m, min_value = 0, only_upper = F, diag = T)
tcrossprod_sparse(m, min_value = 0, only_upper = F, diag = F)
tcrossprod_sparse(m, min_value = 0, only_upper = T, diag = F)
tcrossprod_sparse(m, min_value = 0.2, only_upper = T, diag = F)
tcrossprod_sparse(m, min_value = 0, only_upper = T, diag = F, top_n = 1)

## filtering by group/date. Documents have to be in the same group, or within the given date range
m = Matrix::rsparsematrix(10,10,0.5)
tcrossprod_sparse(m, group = c(1,1,1,2,2,2,3,3,3,3))

date = seq.Date(as.Date('2010-01-01'), as.Date('2010-01-10'), by=1)
tcrossprod_sparse(m, date = date, lwindow = -1, rwindow = 1)
tcrossprod_sparse(m, date = date, lwindow = -2, rwindow = 2)

## using min(x,y) instead of prod(x,y) 
m = abs(Matrix::rsparsematrix(10,10,0.5))

tcrossprod_sparse(m, crossfun = 'min')
tcrossprod_sparse(m, crossfun = 'min', rowsum_div = T)
```

Speed seems to be comparable to Matrix::crossprod(), with some speed-ups if filtering is used.
(This needs to be more properly tested)

```{r}
m = abs(Matrix::rsparsematrix(3000,10000,0.1))

## quick and dirty L2 norm (for cosine similarity)
m = as(m, 'dgTMatrix')
norm = sqrt(Matrix::colSums(m^2))
m@x = m@x / norm[m@j+1]
m = as(m, 'dgCMatrix')

## verify that crossprod results are identical
cp1 = tcrossprod_sparse(m)
cp2 = tcrossprod(m)
identical(as(cp1, 'dgCMatrix'), as(cp2, 'dgCMatrix'))

## regular
microbenchmark(tcrossprod_sparse(m),
               tcrossprod((m)),
               times=2)

## only calculate upper triangle and do not calculate diagonal
microbenchmark(tcrossprod_sparse(m, only_upper = T, diag = F),
               tcrossprod((m)),
               times=2)

## add minimum value
microbenchmark(tcrossprod_sparse(m, min_value = 0.5, only_upper = T, diag = F),
               tcrossprod((m)),
               times=2)
```


Now, using a large matrix (50,000 rows), that would normally crash unless you have a good chunk of memory (worst case scenario: 50.000 \* 50.000 \* 8 bytes). Here we use the top_n filter, for which the required memory is at most nrow(m) \* top_n \* 8 bytes. We also use the verbose option to display a progress bar.

```{r, eval=F}
m = abs(Matrix::rsparsematrix(50000,20000,0.001))

cp = tcrossprod_sparse(m, top_n = 10, verbose=T)
```

Finally, we'll use the group/date filter, which very large matrices (1,000,000 rows) to be processed by limiting comparisons to articles within the same group and/or date range.  

```{r, eval=F}
m = abs(Matrix::rsparsematrix(1000000,20000,0.001))

date = seq.Date(as.Date('1000-01-01'), as.Date('4010-01-10'), by=1)[1:nrow(m)] ## just to make 1,000,000 days
cp = tcrossprod_sparse(m, date=date, lwindow = 15, rwindow=15, verbose=T)
```

